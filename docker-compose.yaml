version: '3'

services:
  # Spark w/ Hudi & Jupyter
  spudi:
    container_name: spudi
    build:
      context: ./spark
      dockerfile: Dockerfile
    ports:
      - "8088:8888"
    # Creates a local directory for storing development code that can be used inside the container as well
    volumes:
      - ./localdevelopment:/opt/bitnami/spark/localdevelopment
    env_file:
      - ./spark/config
    networks:
      - local
  # Zookeeper is required to run Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    env_file:
      - ./kafka/config
    networks:
      - local
  # Apache Kafka
  kafka-broker:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka-broker
    ports:
    # To learn about configuring Kafka for access across networks see
    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - "9092:9092"
    depends_on:
      - zookeeper
    env_file:
      - ./kafka/config
    networks:
      - local

networks:
  local: