version: '3'

services:
  # Spark w/ Hudi & Jupyter
  spudi:
    container_name: spudi
    build:
      context: ./spark
      dockerfile: Dockerfile
    ports:
      - 8088:8888
    # Creates a local directory for storing development code that can be used inside the container as well
    volumes:
      - ./localdevelopment:/opt/bitnami/spark/localdevelopment
    networks:
      - local
  # Zookeeper is required to run Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOO_MY_ID: 1
    networks:
      - local
  # Apache Kafka
  kafka-broker:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka-broker
    ports:
    # To learn about configuring Kafka for access across networks see
    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:9092,PLAINTEXT_INTERNAL://kafka-broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - local
networks:
  local: